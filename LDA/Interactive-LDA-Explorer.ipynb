{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "This notebook expects a document-topic matrix and term-topic matrix, both in parquet format and in the same directory. It also expects a settings.json file in the same directory. The settings file mostly just points to information about the original text, so you can run it without them and follow the errors. The data path, index column, and text column should be all that you need to change, which is just three strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Click here](#settings) to edit paths and/or column names.\n",
    "\n",
    "[Click here](#interactive-display) to jump to results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Reporting\n",
    "\n",
    "You will see some numbers by the topics, which represent the average distribution of that topic across all documents in the corpus. That number is OK to use and think about, however do not use that number in conjunction with human naming of topics. Also avoid reporting that number to casual audiences who do not fully grasp the difference between human understandable topics and machine topics. Even unlikely words that you won't look at can matter since there are so many."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Combobox\n",
    "from IPython.display import display, display_html\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    with open(\"settings.json\") as config_file:\n",
    "        settings = json.load(config_file)\n",
    "except:\n",
    "    settings = {}\n",
    "# Necessary pieces of information to know about the file containing the original text.\n",
    "data_path = settings.get(\"data_filepath\",\"Your data filepath here\")\n",
    "nice_text_col = settings.get(\"nice_text_column\",\"Your plain text column here\")\n",
    "index_col = settings.get(\"index_column\",\"Your index col here\") # Column to use as index for dataframe\n",
    "# Other nice things to know\n",
    "model_name = settings.get(\"job_name\",\"Your model file name here\")\n",
    "long_job_name = settings.get(\"long_name\",\"No long job name in config.\")\n",
    "include_metadata = settings.get(\"include_metadata\",False) # Metadata is extra document-level data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the original text for display purposes\n",
    "preprocessed_SES = pd.read_csv(data_path,\n",
    "            usecols = [index_col,nice_text_col])\n",
    "# Set the index manually as I was having some trouble with specifying it in the import statement.\n",
    "preprocessed_SES.set_index(index_col,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Model and create components\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term score is a slightly better metric for word relevance per topic for human consumption especially. v indexes terms while k indexes topics:\n",
    "$$ \\text{term-score}_{v,k} = \\hat \\beta_{v,k} \\log \\left( \\frac{\\hat \\beta_{v,k}}{\\left( \\prod_{j=1}^K \\hat \\beta_{v,j}\\right)^{\\frac{1}{K}}} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row_to_term_score(row):\n",
    "    '''Converts a word-topic row to a term score row. \n",
    "    Input should be a series of probabilities (intent is that the term is the index)'''\n",
    "    normalizer = gmean(row) # Compute geometric mean of the word probabilities\n",
    "    term_score_row = row.apply(lambda b: b*(np.log(b/normalizer))) #applying the transformation\n",
    "    return term_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First grab the matrix of word probabilities\n",
    "term_topic_matrix = pd.read_parquet(\"term-topic.parquet\")\n",
    "# Create Term Score Matrix\n",
    "term_score_matrix = term_topic_matrix.apply(convert_row_to_term_score,axis=1)\n",
    "print(f\"Number of terms: {len(term_score_matrix)}\")\n",
    "print(\"Term Score Examples\")\n",
    "term_score_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Document Topic Matrix\n",
    "document_topic_matrix = pd.read_parquet(\"doc-topic.parquet\")\n",
    "print(f\"Number of documents: {len(document_topic_matrix)}\")\n",
    "print(\"Document Distribution Examples\")\n",
    "document_topic_matrix.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_means = document_topic_matrix.mean().apply(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_responses(topic_name,number_responses,doc_metadata = None):\n",
    "    doc_ids = document_topic_matrix.sort_values(by=topic_name,ascending = False)\n",
    "    doc_ids = doc_ids.index.tolist()[:number_responses]\n",
    "    # Print results\n",
    "    for doc_id in doc_ids:\n",
    "        if doc_metadata is not None: # Check if we want to display metadata with each comment\n",
    "            display(doc_metadata.loc[[doc_id]].style.hide_index())\n",
    "        display_html(\" • \" + preprocessed_SES.loc[doc_id][nice_text_col] + \"<br><br><br>\", raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_responses(topic_name, number_responses, doc_metadata = None):\n",
    "    '''Gives {number_responses} random responses that are dominated by topic {topic_name}'''\n",
    "    relevant_responses = document_topic_matrix[document_topic_matrix.apply(\n",
    "        lambda row: row[topic_name] >= row.max(), # Check if the named topic is at least as large as the largest topic\n",
    "        axis = 1 # Map over rows\n",
    "    )]\n",
    "    doc_ids = relevant_responses.sample(number_responses).index.tolist()\n",
    "    for doc_id in doc_ids:\n",
    "        if doc_metadata is not None: # Check if we want to display metadata with each comment\n",
    "            display(doc_metadata.loc[[doc_id]].style.hide_index())\n",
    "        display_html(\" • \" + preprocessed_SES.loc[doc_id][nice_text_col] + \"<br><br><br>\", raw = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html() + (\"\\xa0\" * 5) # Spaces\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classic Display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top words per topic\n",
    "num_top_words = 14\n",
    "for c in term_score_matrix.columns:\n",
    "    print(f'\\n Topic {c} -- {topic_means[c]} \\n',\n",
    "          term_score_matrix[c]\n",
    "          .sort_values(ascending=False) #Sort most relevant words by their term score in column 'c'\n",
    "          .head(num_top_words) #Take top ten most relevant words\n",
    "          .index #The index is the word itself\n",
    "          .tolist() #Feel free to replace with some nicer display function\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(word = Combobox(options = list(term_score_matrix.index)), continuous_update = False, value = \"class\")\n",
    "def plot_term(word = \"class\"):\n",
    "    try:\n",
    "        display_html(f\"<h4> Probability(term|topic) for \\\"{word}\\\"\",raw=True)\n",
    "        display_html(term_topic_matrix.loc[[word]].transpose().plot.bar(ylabel = \"Conditional term probability\",xlabel = \"Topic\"))\n",
    "    except KeyError as e: print(\"Waiting for valid input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most relevant words by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(topic = document_topic_matrix.columns, num = (5,100), cols = (1,10),include_term_score = True)\n",
    "def top_words(topic,num = 30, cols = 4, include_term_score = True):\n",
    "    sorted_term_score = term_score_matrix.sort_values(by = topic, ascending = False)[[topic]] # Prepare terms sorted by score\n",
    "    sorted_term_score.columns = [\"Term Score\"]\n",
    "    display_html(f\"<h4><u> Most Relevant words for Topic {topic} ({topic_means[topic]}):\", raw = True) # Heading\n",
    "    if include_term_score:\n",
    "        per_col = int(np.ceil(num/cols)) # Figure out how many words to put per column\n",
    "        display_side_by_side(*[sorted_term_score.iloc[x: x + per_col] for x in range(0,num,per_col)]) # Display the columns. *[] used to partition the dataframe\n",
    "    else:\n",
    "        print(sorted_term_score.head(num).index.tolist()) # Print them out plainly if we want that for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responses that most identify with a particular topic in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    topic = document_topic_matrix.columns, # Choose a topic from the doc-topic matrix\n",
    "    number_responses = [4,20,50,100,500], # Choose a number of responses\n",
    "    include_topic_distributions = False # Choose whether you want to show the entry from the doc-topic matrix for each response\n",
    ")\n",
    "def top_resp(topic, number_responses = 4, include_topic_distributions = False):\n",
    "    if include_topic_distributions:\n",
    "        metadata = document_topic_matrix # Set the metadata to display and populate it\n",
    "    else: metadata = None\n",
    "    display_html(f\"<h2><u> Top Responses for Topic {topic} ({topic_means[topic]}):\", raw = True)\n",
    "    return get_top_responses(topic_name = topic, number_responses = number_responses, doc_metadata = metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly sample responses dominated by a particular topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    topic = document_topic_matrix.columns, # Choose which topic you want to see responses from\n",
    "    number_responses = [1,5,10,20,50,100,500], # How many random responses you want to see\n",
    "    include_topic_distributions = False, # Choose to see the topic distribution for each comment\n",
    "    click_for_new = False # Box to click to get new responses\n",
    ")\n",
    "def random_resp(topic,number_responses = 1, include_topic_distributions = False, click_for_new = False):\n",
    "    if include_topic_distributions:\n",
    "        metadata = document_topic_matrix # Set the metadata to display and populate it\n",
    "    else: metadata = None\n",
    "    display_html(f\"<h2><u> Random Responses most represented by Topic {topic} ({topic_means[topic]}):\", raw = True)\n",
    "    return get_random_responses(topic_name = topic, number_responses = number_responses, doc_metadata = metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
