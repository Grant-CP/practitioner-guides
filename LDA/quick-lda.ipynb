{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "This document is intended as a fast way to get an idea of what LDA can produce. Actual research should be done using a full experimental process including the use of the \"LDA Job manager\" notebook.\n",
    "\n",
    "To make and inspect a quick topic model:\n",
    "1. Make sure that you are using a fully functional notebook viewer, such as VS Code (best) or Jupyter Notebooks. Use options like the ability to collapse sections or input cells. Other options, like Jupyter Lab or custom web views, can be configured to work, but that's on you.\n",
    "1. Prepare a dataset with at least columns for a unique document ID number and text you want to process, with a single textual response per row. LDA does not require preprocessed text to function, but it is easier to interpret results if you use the preprocessing notebook first.\n",
    "1. Edit the data import section ([click here](#data)) with the path, columns names etc for your dataset.\n",
    "1. Run the notebook\n",
    "1. Look at the results in the model inspection section ([click here](#model-inspection))\n",
    "1. If you want to try looking at particular subsets of your data look at the examples section ([click here](#examples-of-how-to-look-at-subsets-of-your-set-of-documents))\n",
    "1. Keep in mind that LDA works best on a large textual dataset (many comments), where each comment is long. We didn't find the need to remove short comments, but you need long comments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, Combobox\n",
    "from IPython.display import display, display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_col = \"unique_comment_ID\" # Unique number/code for each document\n",
    "text_col = \"Preprocessed answer\" # Text to be fed to LDA\n",
    "nice_text_col = \"answer\" # Unprocessed text for viewing. Can be same as text_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/azureuser/cloudfiles/code/Data/pp-20210830_SES_and_SET.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(data_path) # Import data\n",
    "raw_df.set_index(index_col, inplace=True) # Set the document index as index\n",
    "raw_df.dropna(subset=[text_col],inplace=True) # Remove all rows with empty or missing text\n",
    "raw_df[text_col] = raw_df[text_col].astype('string') # make sure the text columns is all strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If your dataset is large, you may want to reduce the size of raw_df by selecting rows to reduce computation time intially. For instance, we normally choose to look at comments only from our newer SES survey, even though that makes up 250k of 1.5 million textual responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(f\"Number of comments: {len(raw_df)}\")\n",
    "raw_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim Components from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is helpful if you want to understand the various steps to feeding textual data into a computational framework like Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = raw_df[[text_col]].applymap(str.split)\n",
    "texts.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(texts[text_col])\n",
    "display(f\"Number of Words: {len(dictionary)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [*dictionary.token2id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = texts.applymap(dictionary.doc2bow)\n",
    "corpus.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html() + (\"\\xa0\" * 5) # Spaces\n",
    "    display_html(html_str.replace('<table','<table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should not have to edit anything in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_row_to_term_score(row):\n",
    "    '''Converts a word-topic matrix to a term score matrix. \n",
    "    Input should be a series of probabilities (intent is that the term is the index)'''\n",
    "    normalizer = gmean(row) # Compute geometric mean of the word probabilities\n",
    "    term_score_row = row.apply(lambda b: b*(np.log(b/normalizer))) #applying the transformation\n",
    "    return term_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickLDA(object):\n",
    "    def __init__(self,doc_ids, num_topics = 7):\n",
    "        '''Takes a list of doc ids and creates all the LDA components'''\n",
    "        self.doc_ids = list(corpus.loc[doc_ids].index) # Making sure this is ordered correctly. Probably not necessary\n",
    "        self.num_topics = num_topics\n",
    "        self.sub_corpus = corpus.loc[doc_ids][text_col] # This is not a dataframe, just an iterable\n",
    "        self.num_docs = len(self.sub_corpus)\n",
    "        self.fit_lda()\n",
    "        self.score_lda()\n",
    "        self.make_term_matrices()\n",
    "        self.make_doc_topic_matrix()\n",
    "\n",
    "    def fit_lda(self):\n",
    "        lda = LdaModel(\n",
    "            id2word = dictionary,\n",
    "            passes = int(np.ceil(50000/self.num_docs)), # Extra fitting for small corpi\n",
    "            num_topics = self.num_topics,\n",
    "            alpha = \"auto\"\n",
    "        )\n",
    "        lda.update(self.sub_corpus)\n",
    "        self.lda = lda\n",
    "\n",
    "    def score_lda(self):\n",
    "        self.perplexity = 2**(-self.lda.log_perplexity(self.sub_corpus))\n",
    "        c_model = CoherenceModel(\n",
    "            model = self.lda,\n",
    "            texts = texts.loc[self.doc_ids][text_col], #Again can't have dataframe\n",
    "            dictionary = dictionary,\n",
    "            coherence = \"c_v\"\n",
    "        )\n",
    "        self.cv_score = c_model.get_coherence()\n",
    "        \n",
    "    def make_term_matrices(self):\n",
    "        self.term_topic_matrix = pd.DataFrame(self.lda.get_topics()).transpose()\n",
    "        self.term_topic_matrix.rename(\n",
    "            index = dictionary.id2token,\n",
    "            inplace=True\n",
    "        )\n",
    "        self.term_score_matrix = self.term_topic_matrix.apply(convert_row_to_term_score,axis=1)\n",
    "        \n",
    "    def make_doc_topic_matrix(self):\n",
    "        document_topic_matrix = pd.DataFrame(\n",
    "            [{doc_tuple[0]:doc_tuple[1] for doc_tuple in doc_tuple_list} for doc_tuple_list in self.lda[self.sub_corpus]])\n",
    "        # Fill Missing Values\n",
    "        document_topic_matrix.fillna(0,inplace = True)\n",
    "        # Sort columns by topic number\n",
    "        document_topic_matrix = document_topic_matrix.reindex(sorted(document_topic_matrix.columns), axis=1)\n",
    "        document_topic_matrix.index = self.sub_corpus.index\n",
    "        self.document_topic_matrix = document_topic_matrix\n",
    "        self.topic_means = document_topic_matrix.mean().apply(lambda x: round(x, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Visuals Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_term(lda, word = \"class\"):\n",
    "    try:\n",
    "        display_html(f\"<h4> Probability(term|topic) for \\\"{word}\\\"\",raw=True)\n",
    "        display_html(lda.term_topic_matrix.loc[[word]].transpose().plot.bar(ylabel = \"Conditional term probability\",xlabel = \"Topic\"))\n",
    "    except KeyError as e: print(\"Waiting for valid input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_responses(topic_name,number_responses,lda, doc_metadata = None, max_words = 1000):\n",
    "    doc_ids = lda.document_topic_matrix.sort_values(by=topic_name,ascending = False)\n",
    "    doc_ids = doc_ids.index.tolist()\n",
    "    doc_ids = list(filter(\n",
    "        lambda doc_id: len(texts.loc[doc_id][text_col]) < max_words, \n",
    "        doc_ids))\n",
    "    doc_ids = doc_ids[:number_responses]\n",
    "    # Print results\n",
    "    for doc_id in doc_ids:\n",
    "        if doc_metadata is not None: # Check if we want to display metadata with each comment\n",
    "            display(doc_metadata.loc[[doc_id]].style.hide_index())\n",
    "        display_html(\" • \" + raw_df.loc[doc_id][nice_text_col] + \"<br><br><br>\", raw = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of how to look at subsets of your set of documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a set of examples showing how to look at particular subsets and a fitting LDA for those subsets. If you have a dataframe you like, an easy way to get the list of document IDs is to use .index.tolist(). I give separate examples here, but you can combine, or bring in your own list of document IDs based on something else like sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all doc_ids for a particular question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example I wanted to get all of the answers to \"what specific change in clarity would help learning\". I use the .isin method to ask if a particular column has a value in a list that I give. So in this case you could write a bunch of question IDs out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clarity_ids = raw_df[raw_df[\"question_ID\"].isin(\n",
    "#     [\"X840307\",\"Your Document Code Here\"]\n",
    "#     )].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_html(\"<h4>Sample Selected Texts:\", raw=True)\n",
    "# for row in raw_df.loc[clarity_ids][nice_text_col].head(3):\n",
    "#     display(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting all Document IDs for a certain list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example looks at all responses containing particular words and does the full LDA exploration for that set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @interact(word = Combobox(options = words,continuous_update = False))\n",
    "# def show_words(word):\n",
    "#     display_html(\"Type in here if you want to see what the kernel thinks are words\", raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Each document will need to contain at least one word from this list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# req_words = [\"canvas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code gets all responses for which the preprocessed answer contains a word from the req_words list. It generates a list of True/False for each word pairing that might agree between the two lists, then \"any\" collapses that into a single True if there was any agreement. The result of apply, which is a dataframe with True/False as it's main column, it used to select a subset of the larger data as usual, then the index is extracted as a list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_doc_ids = texts[texts[text_col].apply(\n",
    "#     lambda tokenized_text: any(word in tokenized_text for word in req_words)\n",
    "# )].index.tolist()\n",
    "# display_html(f\"<b>Number of doc ids: {len(word_doc_ids)}\",raw=True)\n",
    "# display_html(\"<h4>Sample Selected Texts:\",raw= True)\n",
    "# for row in raw_df.loc[word_doc_ids][nice_text_col].head(2):\n",
    "#     display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_lda = QuickLDA(doc_ids=word_doc_ids,num_topics=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After an initial run of the notebook, you only need to rerun these cells and below to change your model and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_ids = raw_df[raw_df[\"survey\"] == \"SES\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_lda = QuickLDA(doc_ids = doc_ids,num_topics= 7) # Fit a topic model on all of the supplied textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = basic_lda # Set the topic model to be inspected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the topic means to make sure that it actually worked. If the topic means seem too focused on one topic, then you need to change the number of topics or select more documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_html(f\"<b> Coherence Score (c_v): </b> {lda.cv_score}\",raw = True)\n",
    "display_html(f\"<b> Perplexity: </b> {lda.perplexity}\",raw = True)\n",
    "display(lda.topic_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the distribution of a particular term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(word = Combobox(options = list(lda.term_score_matrix.index)), continuous_update = False)\n",
    "def f(word):\n",
    "    plot_term(lda,word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw display of top words for all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(show = False,num_top_words = (5,30,100))\n",
    "def relevant_words(show,num_top_words = 14):\n",
    "    # Display top words per topic\n",
    "    if show:\n",
    "        for c in lda.term_score_matrix.columns:\n",
    "            print(f'\\n Topic {c} -- {lda.topic_means[c]} \\n',\n",
    "                lda.term_score_matrix[c]\n",
    "                .sort_values(ascending=False) #Sort most relevant words by their term score in column 'c'\n",
    "                .head(num_top_words) #Take top ten most relevant words\n",
    "                .index #The index is the word itself\n",
    "                .tolist() #Feel free to replace with some nicer display function\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words per Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(topic = lda.document_topic_matrix.columns, num = (5,100), cols = (1,10),include_term_score = True)\n",
    "def top_words(topic,num = 30, cols = 4, include_term_score = True):\n",
    "    sorted_term_score = lda.term_score_matrix.sort_values(by = topic, ascending = False)[[topic]] # Prepare terms sorted by score\n",
    "    sorted_term_score.columns = [\"Term Score\"]\n",
    "    display_html(f\"<h4><u> Most Relevant words for Topic {topic} ({lda.topic_means[topic]}):\", raw = True) # Heading\n",
    "    if include_term_score:\n",
    "        per_col = int(np.ceil(num/cols)) # Figure out how many words to put per column\n",
    "        display_side_by_side(*[sorted_term_score.iloc[x: x + per_col] for x in range(0,num,per_col)]) # Display the columns. *[] used to partition the dataframe\n",
    "    else:\n",
    "        print(sorted_term_score.head(num).index.tolist()) # Print them out plainly if we want that for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Comments by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(\n",
    "    topic = lda.document_topic_matrix.columns, # Choose a topic from the doc-topic matrix\n",
    "    number_responses = [1,5,10,20,100,1000], # Choose a number of responses\n",
    "    max_words = [5,10,20,50,1000], # Max number of words in the responses\n",
    "    include_topic_distributions = False # Choose whether you want to show the entry from the doc-topic matrix for each response\n",
    ")\n",
    "def top_resp(topic, number_responses = 5, include_topic_distributions = False, max_words = 1000):\n",
    "    if include_topic_distributions:\n",
    "        metadata = lda.document_topic_matrix # Set the metadata to display and populate it\n",
    "    else: metadata = None\n",
    "    display_html(f\"<h2><u> Top Responses for Topic {topic} ({lda.topic_means[topic]}):\", raw = True)\n",
    "    return get_top_responses(topic_name = topic, number_responses = number_responses, doc_metadata = metadata, lda = lda, max_words = max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17c92ebe4c347de728263208104da506711e9388d419f2667b4726047bdcfa3c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('azureml_py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
